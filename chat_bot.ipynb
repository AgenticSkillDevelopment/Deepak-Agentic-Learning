{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8ae9ea72",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Published: 2022-08-01\n",
      "Title: The Rise of Quantum Internet Computing\n",
      "Authors: Seng W. Loke\n",
      "Summary: This article highlights quantum Internet computing as referring to\n",
      "distributed quantum computing over the quantum Internet, analogous to\n",
      "(classical) Internet computing involving (classical) distributed computing over\n",
      "the (classical) Internet. Relevant to quantum Internet computing would be areas\n",
      "of study such as quantum protocols for distributed nodes using quantum\n",
      "information for computations, quantum cloud computing, delegated verifiable\n",
      "blind or private computing, non-local gates, and distributed quantum\n",
      "applications, over Internet-scale distances.\n",
      "\n",
      "Published: 2000-03-31\n",
      "Title: Unconventional Quantum Computing Devices\n",
      "Authors: Seth Lloyd\n",
      "Summary: This paper investigates a variety of unconventional quantum computation\n",
      "devices, including fermionic quantum computers and computers that exploit\n",
      "nonlinear quantum mechanics. It is shown that unconventional quantum computing\n",
      "devices can in pri\n",
      "Page: Quantum computing\n",
      "Summary: A quantum computer is a computer that exploits quantum mechanical phenomena. On small scales, physical matter exhibits properties of both particles and waves, and quantum computing takes advantage of this behavior using specialized hardware. Classical physics cannot explain the operation of these quantum devices, and a scalable quantum computer could perform some calculations exponentially faster than any modern \"classical\" computer. Theoretically a large-scale quantum computer could break some widely used encryption schemes and aid physicists in performing phy\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.tools import ArxivQueryRun, WikipediaQueryRun\n",
    "from langchain_community.utilities import ArxivAPIWrapper, WikipediaAPIWrapper\n",
    "\n",
    "# Creating Tools\n",
    "api_wrapper_arxiv = ArxivAPIWrapper(top_k_results=2, doc_content_chars_max=1000)\n",
    "arxiv =  ArxivQueryRun(api_wrapper=api_wrapper_arxiv, description=\"Search for academic papers on arXiv.org\")\n",
    "\n",
    "api_wrapper_wikipedia = WikipediaAPIWrapper(top_k_results=2, doc_content_chars_max=600)\n",
    "wikipedia = WikipediaQueryRun(api_wrapper=api_wrapper_wikipedia, description=\"Search for articles on Wikipedia.org\")\n",
    "\n",
    "print(arxiv.invoke(\"Quantum Computing\"))\n",
    "print(wikipedia.invoke(\"Quantum Computing\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7be4633d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'title': 'Artificial Intelligence News - ScienceDaily', 'url': 'https://www.sciencedaily.com/news/computers_math/artificial_intelligence/', 'content': '![ScienceDaily](/images/sd-logo.png)\\n\\n# Artificial Intelligence News\\n\\n## Top Headlines\\n\\n## Latest Headlines\\n\\n## Earlier Headlines\\n\\n### Wednesday, May 7, 2025\\n\\n### Tuesday, May 6, 2025\\n\\n### Monday, May 5, 2025\\n\\n### Thursday, May 1, 2025\\n\\n### Wednesday, April 30, 2025\\n\\n### Friday, April 25, 2025\\n\\n### Thursday, April 24, 2025\\n\\n### Wednesday, April 23, 2025\\n\\n### Tuesday, April 22, 2025\\n\\n### Tuesday, April 15, 2025\\n\\n### Monday, April 14, 2025\\n\\n### Wednesday, April 9, 2025\\n\\n### Tuesday, April 8, 2025 [...] ### Wednesday, February 19, 2025\\n\\n### Thursday, February 13, 2025\\n\\n### Monday, February 10, 2025\\n\\n### Monday, February 3, 2025\\n\\n### Wednesday, January 29, 2025\\n\\n### Tuesday, January 28, 2025\\n\\n### Monday, January 27, 2025\\n\\n### Tuesday, January 21, 2025\\n\\n### Thursday, January 16, 2025\\n\\n### Wednesday, January 15, 2025\\n\\n### Tuesday, January 14, 2025\\n\\n### Thursday, January 9, 2025\\n\\n### Wednesday, January 8, 2025\\n\\n### Monday, January 6, 2025\\n\\n### Thursday, January 2, 2025 [...] ### Thursday, April 3, 2025\\n\\n### Thursday, March 27, 2025\\n\\n### Wednesday, March 26, 2025\\n\\n### Tuesday, March 25, 2025\\n\\n### Thursday, March 20, 2025\\n\\n### Wednesday, March 19, 2025\\n\\n### Tuesday, March 18, 2025\\n\\n### Monday, March 17, 2025\\n\\n### Thursday, March 6, 2025\\n\\n### Wednesday, March 5, 2025\\n\\n### Tuesday, March 4, 2025\\n\\n### Thursday, February 27, 2025\\n\\n### Wednesday, February 26, 2025\\n\\n### Tuesday, February 25, 2025\\n\\n### Friday, February 21, 2025\\n\\n### Thursday, February 20, 2025', 'score': 0.6768127}, {'title': 'AI News | Latest AI News, Analysis & Events', 'url': 'https://www.artificialintelligence-news.com/', 'content': 'AI News reports on the latest artificial intelligence news and insights. Explore industry trends from the frontline of AI.', 'score': 0.61779}, {'title': 'AI News & Artificial Intelligence - TechCrunch', 'url': 'https://techcrunch.com/category/artificial-intelligence/', 'content': \"### [Scale AI confirms ‘significant’ investment from Meta, says CEO Alexandr Wang is leaving](https://techcrunch.com/2025/06/13/scale-ai-confirms-significant-investment-from-meta-says-ceo-alexandr-wang-is-leaving/)\\n\\n![dripping Facebook Meta logo](https://techcrunch.com/wp-content/uploads/2021/12/dripping-meta-logo.jpg?w=668)\\n\\n### [The Meta AI app is a privacy disaster](https://techcrunch.com/2025/06/12/the-meta-ai-app-is-a-privacy-disaster/) [...] ### [Taiwan places export controls on Huawei and SMIC](https://techcrunch.com/2025/06/15/taiwan-places-export-controls-on-huawei-and-smic/)\\n\\n![The Google logo and lettering can be seen on the facade of the company's Munich headquarters.](https://techcrunch.com/wp-content/uploads/2025/02/GettyImages-2199793091.jpg?w=562)\\n\\n### [Google reportedly plans to cut ties with Scale AI](https://techcrunch.com/2025/06/14/google-reportedly-plans-to-cut-ties-with-scale-ai/) [...] ### [Wikipedia pauses AI-generated summaries pilot after editors protest](https://techcrunch.com/2025/06/11/wikipedia-pauses-ai-generated-summaries-pilot-after-editors-protest/)\\n\\n![Stable Diffusion](https://techcrunch.com/wp-content/uploads/2022/08/ai-gen-unfiltered.jpg?w=668)\\n\\n### [Disney and Universal sue Midjourney, alleging AI-related copyright infringement](https://techcrunch.com/2025/06/11/disney-and-universal-sue-midjourney-alleging-ai-related-copyright-infringement/)\", 'score': 0.5957048}, {'title': 'Artificial Intelligence | Latest News, Photos & Videos - WIRED', 'url': 'https://www.wired.com/tag/artificial-intelligence/', 'content': '### Facing a Changing Industry, AI Activists Rethink Their Strategy\\n\\n![Demis Hassabis Embraces the Future of Work in the Age of AI](https://media.wired.com/photos/683e039d7fcbfb59910b6706/3:2/w_1280%2Cc_limit/DSC09515.jpg)\\n\\n### Demis Hassabis Embraces the Future of Work in the Age of AI\\n\\n### Deepfake Scams Are Distorting Reality Itself\\n\\n![The Rise of ‘Vibe Hacking’ Is the Next AI Nightmare](https://media.wired.com/photos/683dde00bb81c8212495c31b/3:2/w_1280%2Cc_limit/WIRED%2520STILL%252002.png) [...] ### AI Chatbots Are Making LA Protest Disinformation Worse\\n\\n![A Political Battle Is Brewing Over Data Centers](https://media.wired.com/photos/684036ef4c253f09088b983a/3:2/w_1280%2Cc_limit/GettyImages-2213382270.jpg)\\n\\n### A Political Battle Is Brewing Over Data Centers\\n\\n![Apple Is Pushing AI Into More of Its Products&-but Still Lacks a State-of-the-Art Model](https://media.wired.com/photos/684726c94c3cf40b5be20abf/3:2/w_1280%2Cc_limit/Apple-WWDC25-Apple-Intelligence-hero-250609.jpg)', 'score': 0.5786631}, {'title': 'Artificial Intelligence - The New York Times', 'url': 'https://www.nytimes.com/spotlight/artificial-intelligence', 'content': 'A.I. has yet to upend Hollywood. But it is starting to make big inroads in animation.\\n\\n\\xa0By Brooks Barnes\\n\\n![](https://static01.nyt.com/images/2025/04/14/14visualUploader-75672-cover/14visualUploader-75672-cover-square640-v2.jpg?auto=webp)\\n\\n[Google Unveils A.I. Chatbot, Signaling a New Era for Search](/2025/05/20/technology/personaltech/google-ai-mode-search.html)\\n\\nThe tech giant is taking its next big step in artificial intelligence by adding interactive capabilities to its flagship product. [...] By Tripp Mickle\\n\\n![Sundar Pichai, the chief executive of Google, spoke on Tuesday about the company’s plans to bring more generative A.I. abilities to its flagship search product during its annual developers conference. ](https://static01.nyt.com/images/2025/05/20/multimedia/20biz-google-sundar-lbtm/20biz-google-sundar-lbtm-square640.jpg?auto=webp)\\n\\n[A New App Uses A.I. to Speed Jewelry Design](/2025/05/20/fashion/jewelry-blng-artificial-intelligence-app.html) [...] ![Mark Zuckerberg’s new A.I. lab aims to hire some of the top A.I. researchers in the world.](https://static01.nyt.com/images/2025/06/12/multimedia/00biz-superintelligence-ljkv/00biz-superintelligence-ljkv-smallSquare252.jpg?auto=webp)\\n\\n### [This A.I. Company Wants to Take Your Job](/2025/06/11/technology/ai-mechanize-jobs.html)\\n\\nMechanize, a San Francisco start-up, is building artificial intelligence tools to automate white-collar jobs “as fast as possible.”\\n\\n\\xa0By Kevin Roose', 'score': 0.5585443}]\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.tools.tavily_search import TavilySearchResults\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "import os\n",
    "\n",
    "os.environ[\"TAVILY_API_KEY\"] = os.getenv(\"TAVILY_API_KEY\")\n",
    "os.environ[\"GROQ_API_KEY\"] = os.getenv(\"GROQ_API_KEY\")\n",
    "\n",
    "tavily = TavilySearchResults()\n",
    "\n",
    "print(tavily.invoke(\"provide me the recent AI news\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ce96e784",
   "metadata": {},
   "outputs": [],
   "source": [
    "tools = [arxiv, wikipedia, tavily]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1ad1f0e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_groq import ChatGroq\n",
    "\n",
    "llm = ChatGroq(model = \"qwen-qwq-32b\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bfa3bfe8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"\\n<think>\\nOkay, the user is asking about the latest LLM model from Qwen. Let me start by recalling what I know about Qwen's models. I remember that Qwen has several versions, like Qwen1, Qwen1.5, Qwen2, and so on. The latest one I know of is Qwen2.5. I should confirm that.\\n\\nWait, but maybe there's an even newer version now? Sometimes companies release updates without much fanfare. Let me think. The user might be looking for the latest available as of the current date. Since I can't check real-time data, I'll have to go with what's documented up to my last update in December 2024.\\n\\nSo, Qwen2.5 is the most recent version mentioned in the official documentation. It's an improvement over previous models with better performance, efficiency, and larger context lengths. I should mention the key features of Qwen2.5, like the context window, training data, and capabilities. Also, it's important to highlight that different versions cater to different use cases, so users might prefer one over another depending on their needs.\\n\\nI should also note that Qwen offers various specialized models like Qwen-Audio, which handles audio, and Qwen-VL for visual tasks. Maybe the user is interested in those as well. But the main question is about the latest LLM model, so focusing on Qwen2.5 is key.\\n\\nAdditionally, mentioning where to find the latest information is crucial because things can get outdated quickly. Directing them to Qwen's official website or GitHub repository would be helpful. Also, if there's a version beyond 2.5 that's not widely known yet, I should advise checking the official sources.\\n\\nI need to structure the answer clearly: state the latest version, its features, the base models, and specialized variants. Keep it concise but informative. Avoid technical jargon where possible, but still provide enough detail to satisfy the user's curiosity. Make sure to include any notable improvements over previous models, like training data up to a certain date, which adds credibility.\\n\\nWait, did Qwen2.5 have any significant changes in terms of parameters or training data? Let me recall: context window increased to 32k, training data up to December 2024. That's a key point. Also, the specialized models like Qwen-Audio2.5 and Qwen-VL2.5 are part of the same series, so mentioning them shows that the update applies to those too.\\n\\nI should also consider if there's a model specifically designed for code, like the Qwen-Max series. Maybe Qwen-Max3 or something similar? Hmm, not sure. I think the Max series is more about performance, so perhaps Qwen-Max is part of the 2.5 family? Wait, in the previous info, Qwen-Max is a separate specialized model. So, in the answer, list the base models (2.5, 2, 1.5, 1) and then the specialized ones.\\n\\nOkay, putting it all together: start with the latest version (2.5), its features, then the other versions, specialized models, and where to find more info. Make sure to clarify that the user can check official sources for the absolute latest updates, just in case there's a newer version I'm not aware of.\\n</think>\\n\\nAs of December 2024, the latest version of the Qwen Large Language Model (LLM) is **Qwen2.5**. This model builds on previous iterations (Qwen1, Qwen1.5, Qwen2) with significant improvements in performance, context window size, and training data.\\n\\n### Key Features of Qwen2.5:\\n1. **Larger Context Window**: Supports up to **32,768 tokens** (context length), enabling handling of longer documents and complex tasks.\\n2. **Enhanced Performance**: Better accuracy and reasoning capabilities compared to earlier models.\\n3. **Training Data**: Trained on a vast dataset up to December 2024, ensuring up-to-date knowledge.\\n4. **Efficiency**: Optimized for faster inference and lower latency.\\n5. **Multilingual Support**: Strong performance in multiple languages, including Chinese, English, and others.\\n\\n### Model Variants:\\n- **Qwen2.5** (base model): General-purpose LLM.\\n- **Qwen-Audio2.5**: Specialized for **audio tasks** (e.g., speech recognition, voice-to-text).\\n- **Qwen-VL2.5**: Supports **multi-modal tasks**, integrating text, images, and other media.\\n- **Qwen-Max Series**: High-performance variants (e.g., Qwen-Max, Qwen-Max3) for specialized applications.\\n\\n### Why Upgrade to Qwen2.5?\\n- **Improved Accuracy**: Better at complex reasoning and nuanced tasks.\\n- **Expanded Use Cases**: Suitable for advanced applications like code generation, chatbots, and content creation.\\n- **Scalability**: Designed for both individual and enterprise use.\\n\\n### How to Access:\\n- Visit the official **Qwen website** or **GitHub repository** for documentation, APIs, and SDKs.\\n- Check the [Qwen Model Hub](https://modelscope.cn/models) for the latest updates and specialized models.\\n\\nFor the absolute latest information or cutting-edge versions (if released post-December 2024), always refer to Alibaba Cloud's official announcements or the Qwen GitHub page, as updates can be rapid in the LLM space.\\n\\nLet me know if you need details about specific use cases or technical specifications!\", additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 1170, 'prompt_tokens': 17, 'total_tokens': 1187, 'completion_time': 2.732807169, 'prompt_time': 0.003834845, 'queue_time': 0.293986554, 'total_time': 2.736642014}, 'model_name': 'qwen-qwq-32b', 'system_fingerprint': 'fp_a91d9c2cfb', 'finish_reason': 'stop', 'logprobs': None}, id='run--d986120d-96e0-42f0-a8b2-a21040cc67da-0', usage_metadata={'input_tokens': 17, 'output_tokens': 1170, 'total_tokens': 1187})"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm.invoke(\"latest llm model of qwen\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f4644894",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm_with_tools = llm.bind_tools(tools=tools)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b623a56d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing_extensions import TypedDict\n",
    "from langchain_core.messages import AnyMessage\n",
    "from typing import Annotated\n",
    "from langgraph.graph.message import add_messages "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cb106469",
   "metadata": {},
   "outputs": [],
   "source": [
    "class State(TypedDict):\n",
    "    messages: Annotated[list[AnyMessage] , add_messages] # add_messages will append all the messages to the messages varaible and return in the typed dict format, it will not over write \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "db0ff5f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image, display\n",
    "from langgraph.graph import StateGraph, START , END\n",
    "from langgraph.prebuilt import ToolNode\n",
    "from langgraph.prebuilt import tools_condition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46f25d65",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tool_calling_llm(state: State):\n",
    "    return {\"messages\": [llm_with_tools.invoke(state[\"messages\"])]}\n",
    "\n",
    "builder = StateGraph(State)\n",
    "builder.add_node(\"tool_calling_llm\", tool_calling_llm)\n",
    "builder.add_node(\"tools\", ToolNode(tools))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0b99b36",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
